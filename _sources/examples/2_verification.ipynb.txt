{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f4f706",
   "metadata": {},
   "source": [
    "# Verifying derivative calculations\n",
    "\n",
    "This notebook describes the verification of derivative calculations using Taylor remainder convergence testing. A simple time-independent problem is considered, using tlm_adjoint with the [Firedrake](https://firedrakeproject.org/) backend.\n",
    "\n",
    "The Taylor remainder convergence testing method is described in:\n",
    "\n",
    "- P.&nbsp;E.&nbsp;Farrell, D. A. Ham, S. W. Funke, and M. E. Rognes, 'Automated derivation of the adjoint of high-level transient finite element programs', SIAM Journal on Scientific Computing 35(4), pp. C369&ndash;C393, 2013, doi: 10.1137/120873558\n",
    "\n",
    "## Forward problem\n",
    "\n",
    "We consider the solution of a linear time-independent partial differential equation, followed by the calculation of the square of the $L^2$-norm of the solution. Non-linearity is introduced by defining the right-hand-side of the problem to be a non-linear function of the control. We assume real spaces and a real build of Firedrake throughout.\n",
    "\n",
    "Specifically we consider the solution $u \\in V$ of\n",
    "\n",
    "$$\n",
    "  \\forall \\zeta \\in V \\qquad \\int_\\Omega u \\zeta + \\alpha^2 \\int_\\Omega \\nabla u \\cdot \\nabla \\zeta = \\int_\\Omega \\left( \\sin^2 m \\right) \\zeta,\n",
    "$$\n",
    "\n",
    "where $V$ is a real $P_1$ continuous finite element space defining functions on the domain $\\Omega = \\left( 0, 1 \\right)^2$, with $m \\in V$. This corresponds to a discretization of the partial differential equation\n",
    "\n",
    "$$\n",
    "    u - \\alpha^2 \\nabla^2 u = \\sin^2 m \\quad \\text{on } \\left( x, y \\right) \\in \\left( 0, 1 \\right)^2,\n",
    "$$\n",
    "\n",
    "subject to boundary conditions $\\nabla u \\cdot \\hat{n} = 0$ on the boundary, where $\\hat{n}$ is an outward unit normal.\n",
    "\n",
    "A simple implementation in Firedrake, with $m = e^x \\sin \\left( \\pi x y \\right)$ and $\\alpha = 0.2$, takes the form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fd669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from firedrake import *\n",
    "\n",
    "mesh = UnitSquareMesh(50, 50)\n",
    "X = SpatialCoordinate(mesh)\n",
    "space = FunctionSpace(mesh, \"Lagrange\", 1)\n",
    "test = TestFunction(space)\n",
    "trial = TrialFunction(space)\n",
    "\n",
    "m = Function(space, name=\"m\")\n",
    "m.interpolate(exp(X[0]) * sin(pi * X[0] * X[1]))\n",
    "\n",
    "alpha = Constant(0.2)\n",
    "\n",
    "u = Function(space, name=\"u\")\n",
    "solve(inner(trial, test) * dx + (alpha ** 2) * inner(grad(trial), grad(test)) * dx\n",
    "      == inner(sin(m) ** 2, test) * dx, u)\n",
    "\n",
    "J = assemble(inner(u, u) * dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29810cbf",
   "metadata": {},
   "source": [
    "## Taylor remainder convergence testing: First order\n",
    "\n",
    "If we have a functional $J$ depending on a control $m$ then we have, given some perturbation direction $\\zeta$, via Taylor expansion,\n",
    "\n",
    "$$\n",
    "  \\left| J \\left( m + \\varepsilon \\zeta \\right) - J \\left( m \\right) \\right| = O \\left( \\varepsilon \\right), \\\\\n",
    "$$\n",
    "$$\n",
    "  \\left| J \\left( m + \\varepsilon \\zeta \\right) - J \\left( m \\right) - \\varepsilon \\frac{dJ}{dm} \\zeta \\right| = O \\left( \\varepsilon^2 \\right).\n",
    "$$\n",
    "\n",
    "That is, $\\zeta$ is some direction in the same space as $m$, which we choose, and then we control the perturbation amplitude using the scalar $\\varepsilon$. The final term in the second absolute value is a directional derivative, which we can compute using the adjoint.\n",
    "\n",
    "This leads to a methodology for verifying a derivative computed using the adjoint method:\n",
    "\n",
    "1. Choose a direction $\\zeta$.\n",
    "2. Choose a number of different values of $\\varepsilon$.\n",
    "3. See if we have second order convergence of the second of the above, to zero.\n",
    "\n",
    "This verifies only the directional derivative with a single direction, but if we wish we can choose a new direction and repeat the test.\n",
    "\n",
    "We can use the `taylor_test` function to perform the test for us. By default this generates a pseudorandom direction and chooses a number of values of $\\varepsilon$. It then computes the quantities on the left-hand-sides of the above equations, computes the orders of convergence between consecutive pairs of values for $\\varepsilon$, and displays the results. It returns the *minimum* order computed for the second case, which in a successful verification should be close to two.\n",
    "\n",
    "Let's compute a derivative using the adjoint method, and apply a Taylor remainder convergence test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1888394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from firedrake import *\n",
    "from tlm_adjoint.firedrake import *\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(33582866)\n",
    "\n",
    "logger = logging.getLogger(\"tlm_adjoint\")\n",
    "logger.setLevel(logging.INFO)\n",
    "root_logger = logging.getLogger()\n",
    "if len(logger.handlers) == 1:\n",
    "    if len(root_logger.handlers) == 1:\n",
    "        root_logger.handlers.pop()\n",
    "    root_logger.addHandler(logger.handlers.pop())\n",
    "\n",
    "reset_manager()\n",
    "\n",
    "mesh = UnitSquareMesh(50, 50)\n",
    "X = SpatialCoordinate(mesh)\n",
    "space = FunctionSpace(mesh, \"Lagrange\", 1)\n",
    "test = TestFunction(space)\n",
    "trial = TrialFunction(space)\n",
    "\n",
    "m = Function(space, name=\"m\")\n",
    "m.interpolate(exp(X[0]) * sin(pi * X[0] * X[1]))\n",
    "\n",
    "alpha = Constant(0.2)\n",
    "\n",
    "\n",
    "def forward(m):\n",
    "    u = Function(space, name=\"u\")\n",
    "    solve(inner(trial, test) * dx + (alpha ** 2) * inner(grad(trial), grad(test)) * dx\n",
    "          == inner(sin(m) ** 2, test) * dx, u)\n",
    "\n",
    "    J = Functional(name=\"J\")\n",
    "    J.assign(inner(u, u) * dx)\n",
    "    return J\n",
    "\n",
    "\n",
    "start_manager()\n",
    "J = forward(m)\n",
    "stop_manager()\n",
    "\n",
    "dJ_dm = compute_gradient(J, m)\n",
    "\n",
    "min_order = taylor_test(forward, m, J_val=J.value, dJ=dJ_dm, seed=1.0e-3)\n",
    "assert min_order > 1.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdd1937",
   "metadata": {},
   "source": [
    "The key changes here are:\n",
    "\n",
    "- To define a `forward` function. `taylor_test` uses this to repeatedly rerun the forward with different values of $\\varepsilon$.\n",
    "- Using `seed` to control the considered values of $\\varepsilon$. If this is too large then the asymptotic orders of convergence may not be seen. If this is too small then the effect of roundoff or iterative solver tolerances may become too large.\n",
    "- Seeding the NumPy pseudorandom number generator. The pseudorandom direction is generated using `numpy.random.random`, and we seed the pseudorandom number generator to improve reproducibility. We could alternatively supply a direction using the `dM` argument.\n",
    "\n",
    "We see the expected first and second orders of convergence.\n",
    "\n",
    "## Taylor remainder convergence testing: Second order\n",
    "\n",
    "Including the next order term in the Taylor expansion leads to\n",
    "\n",
    "$$\n",
    "    \\left| J \\left( m + \\varepsilon \\zeta \\right) - J \\left( m \\right) - \\varepsilon \\frac{dJ}{dm} \\zeta - \\frac{1}{2} \\varepsilon^2 \\left[ \\frac{d}{dm} \\left( \\frac{dJ}{dm} \\zeta \\right) \\right] \\zeta \\right| = O \\left( \\varepsilon^3 \\right).\n",
    "$$\n",
    "\n",
    "Let's use this approach to test Hessian calculations using a `CachedHessian`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ac48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(19986557)\n",
    "\n",
    "H = CachedHessian(J)\n",
    "\n",
    "min_order = taylor_test(forward, m, J_val=J.value, ddJ=H, seed=1.0e-3)\n",
    "assert min_order > 2.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0435ee4",
   "metadata": {},
   "source": [
    "We now see the expected first and *third* orders of convergence, although there is a suggestion of roundoff affecting the results for the smallest $\\varepsilon$. Here the first order directional derivative is computed using a tangent-linear calculation, and the Hessian action on $\\zeta$ is computed by applying the adjoint method to the forward and tangent-linear calculations.\n",
    "\n",
    "## Taylor remainder convergence testing: Higher order\n",
    "\n",
    "We can test the derivative of a directional derivative, if we substitute\n",
    "\n",
    "$$\n",
    "  J \\rightarrow K = \\frac{dJ}{dm} \\zeta_0,\n",
    "$$\n",
    "\n",
    "with some *new* direction $\\zeta_0$, which we choose. That is, we use\n",
    "\n",
    "$$\n",
    "  \\left| K \\left( m + \\varepsilon \\zeta \\right) - K \\left( m \\right) \\right| = O \\left( \\varepsilon \\right), \\\\\n",
    "$$\n",
    "$$\n",
    "  \\left| K \\left( m + \\varepsilon \\zeta \\right) - K \\left( m \\right) - \\varepsilon \\frac{dK}{dm} \\zeta \\right| = O \\left( \\varepsilon^2 \\right),\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "  K = \\frac{dJ}{dm} \\zeta_0.\n",
    "$$\n",
    "\n",
    "The new term\n",
    "\n",
    "$$\n",
    "  \\frac{dK}{dm} \\zeta\n",
    "$$\n",
    "\n",
    "can be computed using either a higher order tangent-linear or higher-order adjoint calculation. This generalizes naturally to higher order, by replacing the functional with the directional derivative of a directional derivative.\n",
    "\n",
    "The function `taylor_test_tlm` performs such verification tests, considering directional derivatives of a given order, and computing all derivatives using tangent-linear calculations. Each directional derivative requires a new direction to be chosen &ndash; by default pseudorandom directions are generated.\n",
    "\n",
    "Let's apply this test up to fourth order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5bf325",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(76149511)\n",
    "\n",
    "for order in range(1, 5):\n",
    "    min_order = taylor_test_tlm(forward, m, tlm_order=order, seed=1.0e-3)\n",
    "    assert min_order > 1.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df687375",
   "metadata": {},
   "source": [
    "The function `taylor_test_tlm_adjoint` also performs such verification tests, but computes the highest order derivative information using the adjoint method.\n",
    "\n",
    "Let's apply this test up to fourth order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9404e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(74728054)\n",
    "\n",
    "for order in range(1, 5):\n",
    "    min_order = taylor_test_tlm_adjoint(forward, m, adjoint_order=order, seed=1.0e-3)\n",
    "    assert min_order > 1.99"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
